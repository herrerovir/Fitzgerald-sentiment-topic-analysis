{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6170ce0",
   "metadata": {},
   "source": [
    "# Preparing the Texts\n",
    "### Downloading and Cleaning F. Scott Fitzgerald’s Novels for NLP Analysis\n",
    "\n",
    "This notebook handles collecting and cleaning several of F. Scott Fitzgerald’s novels from Project Gutenberg. Metadata such as headers, footers, and appendices are removed, formatting and punctuation are normalized, and the texts are prepared for NLP tasks like sentiment analysis and topic modeling.\n",
    "\n",
    "The cleaned output is saved as sentence-per-line `.txt` files, with one file for each book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c4a556",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3526a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ../notebooks/setup_path.py\n",
    "from config import *\n",
    "\n",
    "# Utilities\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Text processing\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb24df55",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "This project explores themes and emotions in F. Scott Fitzgerald’s works using natural language processing techniques. The texts were obtained from Project Gutenberg, which provides free access to three of his novels: *This Side of Paradise*, *The Beautiful and Damned*, and *The Great Gatsby*.\n",
    "\n",
    "*Tender Is the Night* is not yet in the public domain and is therefore excluded from this analysis. Likewise, Fitzgerald’s unfinished final novel, *The Last Tycoon*, published posthumously, is not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b86d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading this-side-of-paradise...\n",
      "File sucessfully saved!\n",
      "\n",
      "Downloading the-beautiful-and-damned...\n",
      "File sucessfully saved!\n",
      "\n",
      "Downloading the-great-gatsby...\n",
      "File sucessfully saved!\n",
      "\n",
      "All downloads completed!\n"
     ]
    }
   ],
   "source": [
    "# Download and save each book\n",
    "for title, url in BOOK_URLS.items():\n",
    "    print(f\"Downloading {title}...\")\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        filepath = RAW_DIR / f\"{title}.txt\"\n",
    "        with open(filepath, \"w\", encoding = \"utf-8\") as f:\n",
    "            f.write(response.text)\n",
    "        print(f\"File sucessfully saved!\\n\")\n",
    "    else:\n",
    "        print(f\"Failed to download {title} from {url}\\n\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "print(\"All downloads completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b734760",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "The raw texts from Project Gutenberg contain metadata, headers, footers, and other content that introduce noise into the analysis. To prepare the data for processing, a set of helper functions is used to clean and structure the text:\n",
    "\n",
    "- `detect_narrative_start`: Finds where the actual story begins by matching characteristic first lines, allowing the script to skip over prefaces and metadata.\n",
    "- `remove_appendix`: Removes the appendix section from *This Side of Paradise* based on a known heading.\n",
    "- `normalize_chapter_headings`: Standardizes chapter formatting across all books by converting chapter numbers to Roman numerals where needed.\n",
    "- `move_chapter_titles_to_new_line`: Ensures chapter headings appear on their own lines, even when embedded mid-paragraph.\n",
    "- `clean_gutenberg_text_for_sentiment`: Cleans and normalizes punctuation, removes Gutenberg footer and appendix, and strips unwanted characters.\n",
    "- `get_sentences`: Tokenizes the cleaned text into individual sentences using NLTK, preparing the data for sentiment and thematic analysis.\n",
    "\n",
    "Using these modular functions helps keep the cleaning pipeline organized and easier to maintain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbb0fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: find the actual start of narrative\n",
    "def detect_narrative_start(text):\n",
    "    \"\"\"\n",
    "    Detects the start of the main narrative in the text by matching known \n",
    "    opening lines from each book. This helps remove introductory material \n",
    "    like title pages or prefaces.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "        text (str): The full raw text of the book.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "        str: The text starting from the detected beginning of the narrative.\n",
    "    \"\"\"\n",
    "    patterns = [\n",
    "        r\"^\\s*Amory Blaine inherited\",                             # First line of This Side of Paradise\n",
    "        r\"^\\s*In 1913, when Anthony Patch was twenty[- ]?five\",    # First line of The Beautiful and Damned\n",
    "        r\"^\\s*In my younger and more vulnerable years\"             # First line of The Great Gatsby        \n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "        if match:\n",
    "            return text[match.start():]\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a41de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: remove appendix from \"This Side of Paradise\"\n",
    "def remove_appendix(text):\n",
    "    \"\"\"\n",
    "    Removes the appendix from 'This Side of Paradise' starting from the \n",
    "    known appendix heading to the end of the text. This prevents non-narrative \n",
    "    metadata from polluting downstream analysis.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "        text (str): The cleaned book text that may include an appendix.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "        str: The text with the appendix removed.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"\\n\\s*Appendix: Production notes for eBook edition 11.*\", re.DOTALL | re.IGNORECASE)\n",
    "    cleaned_text = re.sub(pattern, \"\", text)\n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac3e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_chapter_headings(text, title):\n",
    "    \"\"\"\n",
    "    Standardizes chapter headings across different books by:\n",
    "    \n",
    "    - Adding \"CHAPTER I\" to the beginning of the text.\n",
    "    - Converting Arabic chapter numbers (e.g., \"CHAPTER 1\") to Roman numerals \n",
    "      for \"This Side of Paradise\", assuming chapters 1–5 only.\n",
    "    - Replacing inline Roman numerals with \"CHAPTER <numeral>\" in \"The Great Gatsby\"\n",
    "      when they appear before a capitalized word (e.g., chapter titles).\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "        text (str): The raw or cleaned book text.\n",
    "        title (str): The title key of the book used to apply title-specific rules.\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "        str: The text with normalized chapter headings.\n",
    "    \"\"\"\n",
    "    text = \"CHAPTER I\\n\" + text\n",
    "\n",
    "    if title == \"this-side-of-paradise\":\n",
    "        # Map Arabic numbers 1-5 to Roman numerals\n",
    "        number_map = {\n",
    "            '1': 'I',\n",
    "            '2': 'II',\n",
    "            '3': 'III',\n",
    "            '4': 'IV',\n",
    "            '5': 'V'\n",
    "        }\n",
    "\n",
    "        def repl(match):\n",
    "            num = match.group(1)\n",
    "            roman = number_map.get(num, num)  # fallback just in case\n",
    "            return f\"CHAPTER {roman}\"\n",
    "\n",
    "        # Replace \"CHAPTER <number>\" with \"CHAPTER <Roman>\n",
    "        text = re.sub(r\"CHAPTER (\\d+)\", repl, text)\n",
    "\n",
    "    if title == \"the-great-gatsby\":\n",
    "        roman_numerals = [\"X\", \"IX\", \"VIII\", \"VII\", \"VI\", \"V\", \"IV\", \"III\", \"II\", \"I\"]\n",
    "        for numeral in roman_numerals:\n",
    "            pattern = rf\"(?<= )({numeral})(?= [A-Z])\"\n",
    "            text = re.sub(pattern, f\"CHAPTER {numeral}\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d294ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_chapter_titles_to_new_line(text):\n",
    "    \"\"\"\n",
    "    Ensures that chapter titles (e.g., \"CHAPTER I\", \"CHAPTER 1\") start on a new line,\n",
    "    even if they appear in the middle of a paragraph or sentence.\n",
    "\n",
    "    Matches both Roman numerals and Arabic digits following the word \"CHAPTER\".\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "        text (str): The input text containing chapter headings.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        str: Modified text where all chapter titles begin on their own line.\n",
    "    \"\"\"\n",
    "    pattern = r\"(?<!\\n)(?<!^)(\\bCHAPTER\\s+(?:[IVXLCM]+|\\d+)\\b)\"\n",
    "    return re.sub(pattern, r\"\\n\\1\", text, flags = re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f431aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: clean and prepare text\n",
    "def clean_gutenberg_text_for_sentiment(text, title=\"\"):\n",
    "    \"\"\"\n",
    "    Cleans and prepares a Project Gutenberg text for NLP by:\n",
    "    - Normalizing punctuation\n",
    "    - Removing Gutenberg footer and appendix (if applicable)\n",
    "    - Stripping headers and unwanted symbols\n",
    "    - Detecting and starting from the narrative beginning\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "        text (str): The raw text of the book.\n",
    "        title (str): The title of the book (used to apply title-specific rules).\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "        str: Cleaned and normalized text ready for tokenization.\n",
    "    \"\"\"\n",
    "    # Normalize punctuation\n",
    "    text = text.replace(\"“\", '\"').replace(\"”\", '\"') \\\n",
    "               .replace(\"’\", \"'\").replace(\"‘\", \"'\").replace(\"—\", \"-\")\n",
    "    \n",
    "    # Find narrative start\n",
    "    text = detect_narrative_start(text)\n",
    "\n",
    "    # Remove footer\n",
    "    end_pattern = r\"\\*\\*\\* END OF.*?\\*\\*\\*\"\n",
    "    parts = re.split(end_pattern, text, flags=re.IGNORECASE)\n",
    "    if len(parts) > 1:\n",
    "        text = parts[0]\n",
    "\n",
    "    # Remove appendix if it's This Side of Paradise\n",
    "    if \"this-side-of-paradise\" in title.lower():\n",
    "        text = remove_appendix(text)\n",
    "\n",
    "    # Normalize spaces and remove unwanted characters\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9.,!?\\'\"\\s]', '', text)\n",
    "\n",
    "    # Normalize chapter headers and fix formatting\n",
    "    text = normalize_chapter_headings(text, title)\n",
    "    text = move_chapter_titles_to_new_line(text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a3ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(text):\n",
    "    \"\"\"\n",
    "    Splits the input text into individual sentences using NLTK's sentence tokenizer.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "        text (str): A cleaned string of text.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "        list: A list of sentence strings.\n",
    "    \"\"\"\n",
    "    return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e9936",
   "metadata": {},
   "source": [
    "Once the helper functions are defined, the preprocessing pipeline follows these steps:\n",
    "\n",
    "- Load each raw text file,\n",
    "- Clean the content using the defined helper functions,\n",
    "- Tokenize the cleaned text into individual sentences,\n",
    "- Save the resulting sentences to new files in the `data/processed` directory,\n",
    "- And print the first and last five sentences to visually verify the results.\n",
    "\n",
    "This process ensures that the texts are properly structured and ready for downstream NLP tasks such as sentiment analysis and topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b31840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Cleaned Book Summary ==\n",
      "\n",
      "Title: 'This Side Of Paradise'\n",
      "Saved: 5,411 sentences\n",
      "File path: C:\\Users\\Virginia\\Python\\Fitzgerald-sentiment-topic-analysis\\data\\processed\\this-side-of-paradise-cleaned.txt\n",
      "\n",
      "First 5 sentences:\n",
      "\n",
      "  1. CHAPTER I\n",
      "Amory Blaine inherited from his mother every trait, except the stray inexpressible few, that made him worth while.\n",
      "  2. His father, an ineffectual, inarticulate man with a taste for Byron and a habit of drowsing over the Encyclopedia Britannica, grew wealthy at thirty through the death of two elder brothers, successful Chicago brokers, and in the first flush of feeling that the world was his, went to Bar Harbor and met Beatrice O'Hara.\n",
      "  3. In consequence, Stephen Blaine handed down to posterity his height of just under six feet and his tendency to waver at crucial moments, these two abstractions appearing in his son Amory.\n",
      "  4. For many years he hovered in the background of his family's life, an unassertive figure with a face halfobliterated by lifeless, silky hair, continually occupied in \"taking care\" of his wife, continually harassed by the idea that he didn't and couldn't understand her.\n",
      "  5. But Beatrice Blaine!\n",
      "\n",
      "Last 5 sentences:\n",
      "\n",
      "  5407. Rosalind!...\n",
      "  5408. \"It's all a poor substitute at best,\" he said sadly.\n",
      "  5409. And he could not tell why the struggle was worth while, why he had determined to use to the utmost himself and his heritage from the personalities he had passed....\n",
      "  5410. He stretched out his arms to the crystalline, radiant sky.\n",
      "  5411. \"I know myself,\" he cried, \"but that is all.\"\n",
      "------------------------------------------------------------\n",
      "\n",
      "Title: 'The Beautiful And Damned'\n",
      "Saved: 8,240 sentences\n",
      "File path: C:\\Users\\Virginia\\Python\\Fitzgerald-sentiment-topic-analysis\\data\\processed\\the-beautiful-and-damned-cleaned.txt\n",
      "\n",
      "First 5 sentences:\n",
      "\n",
      "  1. CHAPTER I\n",
      " In 1913, when Anthony Patch was twentyfive, two years were already gone since irony, the Holy Ghost of this later day, had, theoretically at least, descended upon him.\n",
      "  2. Irony was the final polish of the shoe, the ultimate dab of the clothesbrush, a sort of intellectual \"There!\n",
      "  3. \"yet at the brink of this story he has as yet gone no further than the conscious stage.\n",
      "  4. As you first see him he wonders frequently whether he is not without honor and slightly mad, a shameful and obscene thinness glistening on the surface of the world like oil on a clean pond, these occasions being varied, of course, with those in which he thinks himself rather an exceptional young man, thoroughly sophisticated, well adjusted to his environment, and somewhat more significant than any one else he knows.\n",
      "  5. This was his healthy state and it made him cheerful, pleasant, and very attractive to intelligent men and to all women.\n",
      "\n",
      "Last 5 sentences:\n",
      "\n",
      "  8236. Why, the very friends who had been most unkind had come to respect him, to know he had been right all along.\n",
      "  8237. Had not the Lacys and the Merediths and the CartwrightSmiths called on Gloria and him at the RitzCarlton just a week before they sailed?\n",
      "  8238. Great tears stood in his eyes, and his voice was tremulous as he whispered to himself.\n",
      "  8239. \"I showed them,\" he was saying.\n",
      "  8240. \"It was a hard fight, but I didn't give up and I came through!\"\n",
      "------------------------------------------------------------\n",
      "\n",
      "Title: 'The Great Gatsby'\n",
      "Saved: 3,406 sentences\n",
      "File path: C:\\Users\\Virginia\\Python\\Fitzgerald-sentiment-topic-analysis\\data\\processed\\the-great-gatsby-cleaned.txt\n",
      "\n",
      "First 5 sentences:\n",
      "\n",
      "  1. CHAPTER I\n",
      " In my younger and more vulnerable years my father gave me some advice that I've been turning over in my mind ever since.\n",
      "  2. \"Whenever you feel like criticizing anyone,\" he told me, \"just remember that all the people in this world haven't had the advantages that you've had.\"\n",
      "  3. He didn't say any more, but we've always been unusually communicative in a reserved way, and I understood that he meant a great deal more than that.\n",
      "  4. In consequence, I'm inclined to reserve all judgements, a habit that has opened up many curious natures to me and also made me the victim of not a few veteran bores.\n",
      "  5. The abnormal mind is quick to detect and attach itself to this quality when it appears in a normal person, and so it came about that in college I was unjustly accused of being a politician, because I was privy to the secret griefs of wild, unknown men.\n",
      "\n",
      "Last 5 sentences:\n",
      "\n",
      "  3402. And as I sat there brooding on the old, unknown world, I thought of Gatsby's wonder when he first picked out the green light at the end of Daisy's dock.\n",
      "  3403. He had come a long way to this blue lawn, and his dream must have seemed so close that he could hardly fail to grasp it.\n",
      "  3404. He did not know that it was already behind him, somewhere back in that vast obscurity beyond the city, where the dark fields of the republic rolled on under the night.\n",
      "  3405. Gatsby believed in the green light, the orgiastic future that year by year recedes before us.\n",
      "  3406. It eluded us then, but that's no mattertomorrow we will run faster, stretch out our arms further  And one fine morning So we beat on, boats against the current, borne back ceaselessly into the past.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"== Cleaned Book Summary ==\")\n",
    "for title in BOOKS: \n",
    "\n",
    "    raw_path = RAW_DIR / f\"{title}.txt\"\n",
    "    clean_path = PROCESSED_DIR / f\"{title}-cleaned.txt\"\n",
    "\n",
    "    # Load raw text\n",
    "    with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_text = f.read()\n",
    "\n",
    "    # Clean and tokenize\n",
    "    cleaned_text = clean_gutenberg_text_for_sentiment(raw_text, title=title)\n",
    "    sentences = get_sentences(cleaned_text)\n",
    "\n",
    "    # Save cleaned sentences\n",
    "    with open(clean_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(sentence + \"\\n\" for sentence in sentences)\n",
    "\n",
    "    # Output summary\n",
    "    print(f\"\\nTitle: '{title.replace('-', ' ').title()}'\")\n",
    "    print(f\"Saved: {len(sentences):,} sentences\")\n",
    "    print(f\"File path: {clean_path}\")\n",
    "\n",
    "    print(\"\\nFirst 5 sentences:\\n\")\n",
    "    for i, sent in enumerate(sentences[:5], 1):\n",
    "        print(f\"  {i}. {sent}\")\n",
    "\n",
    "    print(\"\\nLast 5 sentences:\\n\")\n",
    "    for i, sent in enumerate(sentences[-5:], len(sentences) - 4):\n",
    "        print(f\"  {i}. {sent}\")\n",
    "\n",
    "    print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
